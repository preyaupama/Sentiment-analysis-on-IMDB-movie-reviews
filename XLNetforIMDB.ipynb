{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCeb0ilIx76_"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q simpletransformers\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "import sklearn\n",
        "import torch\n",
        "from torch.cuda import is_available"
      ],
      "metadata": {
        "id": "klDy5hM0zWr6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "SsUjLPVgAVbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training and test data \n",
        "dataset_train = load_dataset('imdb',split='train')\n",
        "train_df=pd.DataFrame(dataset_train)\n",
        "\n",
        "dataset_test = load_dataset('imdb',split='test')\n",
        "test_df=pd.DataFrame(dataset_test)"
      ],
      "metadata": {
        "id": "NvOYyO5jyoTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up hyperparameters"
      ],
      "metadata": {
        "id": "FynQVD-MAKYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The training arguments are adopted from the Yang et al. (2019) XLNet paper.\n",
        "training_arguments = {\n",
        "    'reprocess_input_data': True,\n",
        "    'overwrite_output_dir': True,\n",
        "    'sliding_window': True,\n",
        "    'max_seq_length': 64,\n",
        "    'num_train_epochs': 1,\n",
        "    'learning_rate': 0.00001,\n",
        "    'weight_decay': 0.01,\n",
        "    'train_batch_size': 128,\n",
        "    'fp16': True,\n",
        "    'output_dir': '/outputs/',\n",
        "}"
      ],
      "metadata": {
        "id": "T8oSxYW5zpSq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up CUDA"
      ],
      "metadata": {
        "id": "GTNe29WYAHaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device (preferrably CUDA)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPjD9nyy00wQ",
        "outputId": "5316b64c-98e0-4ac0-9873-68b452af7d8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "qKil3J6RAEUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the logger\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "XLNet_transformers_logger = logging.getLogger('transformers')\n",
        "XLNet_transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# Load the pre-trained base cased XLNet model.\n",
        "XLNet_base_model = ClassificationModel('xlnet', 'xlnet-base-cased', num_labels=2, args=training_arguments, use_cuda=use_cuda) \n",
        "\n",
        "# Train the model with no validation dataset\n",
        "XLNet_base_model.train_model(train_df)\n",
        "\n",
        "# Evaluate the model\n",
        "output = XLNet_base_model.eval_model(test_df, acc=sklearn.metrics.accuracy_score)\n",
        "result = output[0]"
      ],
      "metadata": {
        "id": "MyY4Do0Yz8p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "fOBHtEi2AAdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation Loss:\", result['eval_loss'])\n",
        "print(\"Accuracy:\", result['acc'])\n",
        "Precision = result['tp']/(result['tp'] + result['fp'])\n",
        "print(\"Precision:\", Precision)\n",
        "Recall = result['tp']/(result['tp'] + result['fn'])\n",
        "print(\"Recall:\", Recall)\n",
        "F1_Score = (2 * Precision * Recall)/ (Precision + Recall)\n",
        "print(\"F1-Score:\", F1_Score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMoERJJg-O6R",
        "outputId": "d0d4a878-4709-4194-9ee7-8e61e2dbc201"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Loss: 0.38348051576621583\n",
            "Accuracy: 0.91688\n",
            "Precision: 0.8845188902007084\n",
            "Recall: 0.95896\n",
            "F1-Score: 0.92023645017657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End Remarks\n",
        "- Without any data preprocessing, the base XLNet model achieved 91.7% accuracy on the test set after only 1 epoch.\n",
        "- XLNet is bigger than BERT and its training objective is to predict word in a sequence from any permutation of other words in the sequence which capture relationships among words better. It used 'relative positional encoding' to capture the positional information of words."
      ],
      "metadata": {
        "id": "6MNaeCQ6C8zH"
      }
    }
  ]
}